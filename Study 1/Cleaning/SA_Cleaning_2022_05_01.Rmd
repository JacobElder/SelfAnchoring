---
title: "feedback_merge+clean"
output: html_document
---

```{r}
library(compiler)
library(readbulk) 
library(psych)
library(forcats)
library(igraph)
library(MASS)
library(lme4)
library(cluster)
library(Kendall)
library(readr)
library(psych)
library(igraph)
library(plyr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(tidyr)
library(gtools)
library(sjstats)
library(brms)
library(optimx)
library(igraph)
library(loo)
cOptimx <- cmpfun(optimx)

```

```{r}
setwd("~/Google Drive/Volumes/")
posDf <- read.csv("./Research Project/Trait Network_Behaviral/generating network/output/adjacencyMatrix_p.csv")
posMat <- as.matrix(posDf)
posGraph <- graph.adjacency(posMat)
negDf <- read.csv("./Research Project/Trait Network_Behaviral/generating network/output/adjacencyMatrix_n.csv")
negMat <- as.matrix(negDf)
negGraph <- graph.adjacency(negMat)
```

```{r}
setwd("~/Google Drive/Volumes/Research Project/")
allPosCents <- read.csv("/Volumes/GoogleDrive/My Drive/Volumes/Research Project/Trait Network_Behaviral/generating network/output/allPosCents.csv")
allNegCents <- read.csv("/Volumes/GoogleDrive/My Drive/Volumes/Research Project/Trait Network_Behaviral/generating network/output/allNegCents.csv")
allCombCents <- rbind(allPosCents, allNegCents)
allCombCents$Idx <- 1:296
```

```{r}
mergedRaw <- read_bulk(directory = "./input/Task Data/", extension = ".csv", fun = read.csv)
```


```{r}
mergedRaw$choiceResp[mergedRaw$choiceResp==-99] <- NA
mergedRaw$optionChoice[mergedRaw$optionChoice==-99] <- NA
mergedRaw$SE.keys[mergedRaw$SE.keys=="space"] <- NA
mergedRaw$SE.keys <- as.numeric(mergedRaw$SE.keys)
```


```{r}
mergedRaw <- mergedRaw %>% rename(subID = participant, 
                     trialTotalT1 = trials_2.thisTrialN, 
                     trialTotalT2 = choices.thisTrialN,
                     selfResp = SE.keys,
                     sideChoice = choiceResp)

mergedRaw$trialTotalT1 <- mergedRaw$trialTotalT1 + 1
mergedRaw$trialTotalT2 <- mergedRaw$trialTotalT2 + 1

mergedRawtrain <- mergedRaw[!is.na(mergedRaw$trialTotalT1),]
mergedRawtest <- mergedRaw[!is.na(mergedRaw$trialTotalT2),]

Estimators <- mergedRaw %>% 
  select(subID, Estimator) %>%
  group_by(subID) %>%
  filter(row_number()==1)

rawTrain <- mergedRawtrain %>%
  select(subID, trait, trialTotalT1, selfResp)

rawTest <- mergedRawtest %>%
  select(subID, traitC, trialTotalT2, sideChoice, optionChoice, optionLeft, optionRight)

rawTest <- rawTest %>%
  rename(trait = traitC)

rawTest <- rawTest %>% inner_join(Estimators, by = "subID")
rawTrain <- rawTrain %>% inner_join(Estimators, by = "subID")

mergeTest <- rawTest %>% inner_join(allCombCents, by="trait")
mergeTrain <- rawTrain %>% inner_join(allCombCents, by="trait")

#mergeTest$ingChoice <- ifelse(is.na(mergeTest$ingChoice), NA, ifelse(mergeTest$optionChoice==mergeTest$Estimator, "Ingroup", "Outgroup"))

mergeTest$ingChoice <- ifelse(mergeTest$optionChoice==mergeTest$Estimator, "Ingroup", "Outgroup")
mergeTest$ingChoice <- as.factor(mergeTest$ingChoice)
mergeTest$ingChoiceN <- ifelse(mergeTest$ingChoice=="Ingroup", 1, 0)

```

```{r}
uSubs <- unique(mergeTest$subID)
mergeTest$SE <- NA
mergeTest$novel <- 0

for(i in uSubs){
  testSub <- subset(mergeTest, subID==i)
  trainSub <- subset(mergeTrain, subID==i)
  simMat <- similarity.dice(posGraph)
  
  curNovel <- setdiff(testSub$Idx, trainSub$Idx)
  mergeTest$novel[which(mergeTest$subID==i & mergeTest$Idx %in% curNovel)] <- 1
  
  for(t in 1:nrow(testSub)){
    trialNum <- testSub$trialTotalT2[t]
    curSims <- simMat[trainSub$Idx, testSub$Idx[t]]
    curSelf <- trainSub$selfResp
    curOut <- trainSub$outDegree
    curIn <- trainSub$inDegree
    curRem <- which(is.na(trainSub$selfResp))
    if(length(curRem)>0){
      curSelf <- curSelf[-curRem]
      curSims <- curSims[-curRem]
      curOut <- curOut[-curRem]
      curIn <- curIn[-curRem]
    }
    weightedAve <- sum(curSelf * curSims) / sum(curSelf)
    weightedOutAve <- sum(curSelf * curOut * curSims) / sum(curOut * curSelf)
    weightedInAve <- sum(curSelf * curIn * curSims) / sum(curIn * curSelf)
    mergeTest$SE[mergeTest$subID==i & mergeTest$trialTotalT2==trialNum] <- weightedAve
    mergeTest$oSE[mergeTest$subID==i & mergeTest$trialTotalT2==trialNum] <- weightedOutAve
    mergeTest$iSE[mergeTest$subID==i & mergeTest$trialTotalT2==trialNum] <- weightedInAve
    
  }
  
}
```

# Flag careless task participant

```{r}
sketchMat <- matrix(nrow=length(uSubs),ncol=5)
for(i in 1:length(uSubs) ){
  testSub <- subset(mergeTest, subID==uSubs[i])
  trainSub <- subset(mergeTrain, subID==uSubs[i])
  
  proportionSelfs <- prop.table(table(trainSub$selfResp))
  proportionChoices <- prop.table(table(testSub$sideChoice))
  naSelfs <- sum(is.na(trainSub$selfResp))/length(trainSub$selfResp)
  naChoices <- sum(is.na(testSub$sideChoice))/length(testSub$sideChoice)
  
  sketchMat[i, ] <- c(uSubs[i], max(proportionSelfs), max(proportionChoices), naSelfs, naChoices)
}
colnames(sketchMat) <- c("subID", "propSelf", "propChoice", "naSelf", "naChoice")
sketchMat <- as.data.frame(sketchMat)

# Criteria:
# Over 80% of same self-evaluations
# Over 95% of same choices
# Over 40% missing responses for self-evaluations
# Over 40% missing responses for choices
sketchMat$sketch <- ifelse(sketchMat$propSelf > .80 | sketchMat$propChoice > .95 | sketchMat$naSelf > .40 | sketchMat$naChoice > .40, 1, 0)
```

```{r}
postQs <- read.csv("./input/Qualtrics Data/SA1postQs.csv")
preQs <- read.csv("./input/Qualtrics Data/SA1preQs.csv")
preQs$id[which(duplicated(preQs$id))]
preQs <- preQs %>% group_by(id) %>% filter(duplicated(id) | n()==1)
#preQs <- preQs[-which(duplicated(preQs$id)),]

indDiff <- postQs %>% left_join(preQs, by="id")

# Duplicate IDs?
indDiff$id[which(duplicated(indDiff$id))]

indDiff <- indDiff %>% rename(subID = id)
```

```{r}
indDiff$SCC

# Reverse code Self-Concept Clarity Scale items
SCC_revcols = c("SCC_1", "SCC_2", "SCC_3", "SCC_4", "SCC_5", "SCC_7", 
                 "SCC_8", "SCC_9", "SCC_10", "SCC_12")
indDiff[ ,SCC_revcols] = 6 - indDiff[ ,SCC_revcols]
ind1 <- grep("SCC_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("SCC_12", colnames(indDiff))
ind2<-max(ind2)
# Compute score for Self-Concept Clarity Scale items
indDiff$SCC = rowMeans(indDiff[,ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])

psych::omega(indDiff[ind1:ind2])
```

Singelis Self-Construal
```{r}
# Compute score for Independence in Singelis Self-Construal Scale
SING.IndCol = c("SING.1", "SING.2", "SING.5", "SING.7", "SING.9", "SING.10", "SING.13", 
                 "SING.15", "SING.18", "SING.20", "SING.22", "SING.24", "SING.25",
                 "SING.27", "SING.29")
indDiff$SING.Ind = rowMeans(indDiff[, SING.IndCol], na.rm = TRUE)
# Compute score for Interdependence in Singelis Self-Construal Scale
SING.InterCol = c("SING.3", "SING.4", "SING.6", "SING.8", "SING.11", "SING.12", 
                   "SING.14", "SING.16", "SING.17", "SING.19", "SING.21", "SING.23",
                   "SING.26", "SING.28", "SING.30")
indDiff$SING.Inter = rowMeans(indDiff[, SING.InterCol], na.rm = TRUE)
# Compute score for Independence - Interdependence in Singelis Self-Construal Scale
indDiff$SING.IndPlus = (indDiff$SING.Ind - indDiff$SING.Inter)

psych::alpha(indDiff[SING.InterCol])
psych::alpha(indDiff[SING.IndCol])
```
Self-Esteem
```{r}
# Reverse code Rosenberg Self-Esteem items
SErevcols = c("RSE.2", "RSE.5", "RSE.6", "RSE.8", "RSE.9")
indDiff[ ,SErevcols] = 5 - indDiff[ ,SErevcols]
ind1 <- grep("RSE.1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("RSE.10", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Rosenberg Self-Esteem
indDiff$RSE = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items
NFCrevcols = c("NFC.6_3", "NFC.6_4")
indDiff[ ,NFCrevcols] = 8 - indDiff[ ,NFCrevcols]
ind1 <- grep("NFC.6_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("NFC.6_6", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$NFC = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items
NTBrevcols = c("NTB_1", "NTB_3", "NTB_7")
indDiff[ ,NTBrevcols] = 6 - indDiff[ ,NTBrevcols]
ind1 <- grep("NTB_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("NTB_10", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$NTB = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items


#DSrevcols = c("DS_1", "DS_5", "DS_6", "DS_7", "DS_9", "DS_14")
DSrevcols <- "DS_1"
indDiff[ ,DSrevcols] = 8 - indDiff[ ,DSrevcols]
ind1 <- grep("DS_1", colnames(indDiff))
ind1<-min(ind1)
#ind2<- grep("DS_14", colnames(indDiff))
ind2<- grep("DS_17", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$DS = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
ind1 <- grep("Proto_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("Proto_4", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$Proto = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)


psych::alpha(indDiff[ind1:ind2])
```


```{r}
indDiff <- indDiff %>% rename(conf = Off4_1, decep = Off5)

indDiffs <- indDiff %>% select(subID, ConDeb, conf, decep, Serious, UnderstandIns, UnderstandTr, Usable, DS, Proto, SCC, SI, RSE, NTB, NFC, SING.Ind, SING.Inter)

sketchMat <- indDiffs %>% select(subID, ConDeb, conf, decep, Serious, UnderstandIns, UnderstandTr, Usable) %>% inner_join(sketchMat, by = "subID")

sketchMat$remove <- ifelse(sketchMat$sketch > 0 | sketchMat$ConDeb == 2 | sketchMat$Usable == 2 | sketchMat$Serious < 4, 1, 0 | sketchMat$decep == 3)
```

```{r}
unique(mergeTest$subID)
cleanTest <- mergeTest[mergeTest$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(cleanTest$subID)
```

```{r}
unique(mergeTrain$subID)
cleanTrain <- mergeTrain[mergeTrain$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(cleanTrain$subID)
```

```{r}
unique(indDiffs$subID)
indDiffsclean <- indDiffs[indDiffs$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(indDiffsclean$subID)
```

```{r}
fullTest <- cleanTest %>% inner_join(indDiffsclean, by = "subID")
write.csv(fullTest, "./output/fullTest.csv", row.names = F)
```

```{r}
fullTest$optionChoiceN <- ifelse(fullTest$optionChoice=="Overestimator", 1, 0)
traitFreqOverUnder <- Rmisc::summarySE(fullTest, measurevar="optionChoiceN", groupvars = "trait")
write.csv(fullTest, "./output/traitFreqOverUnder.csv", row.names = F)
```



```{r}
fulldf <- fullDf
fulldf$result <- fulldf$choiceProp/100
fulldf$cong <- ifelse(fulldf$pairCong==2, 1, 2)
```

```{r message=FALSE, warning=FALSE}
Idxmat<-cbind(fulldf$IdxLeft, fulldf$IdxRight)
fulldf$IdxChoose <- Idxmat[cbind(seq_along(fulldf$choice), fulldf$choice)]

uIds<-unique(fulldf$subID)

fulldf$SV_L <- NA
fulldf$SV_R <- NA
fulldf$SV2_L <- NA
fulldf$SV2_R <- NA
fulldf$simL <- NA
fulldf$simR <- NA
LIDX <- grep("IdxLeft", colnames(fulldf))
RIDX <- grep("IdxRight", colnames(fulldf))
LVid <- grep("SV_L", colnames(fulldf))
RVid <- grep("SV_R", colnames(fulldf))
LVid2 <- grep("SV2_L", colnames(fulldf))
RVid2 <- grep("SV2_R", colnames(fulldf))
Lsid <- grep("simL", colnames(fulldf))
Rsid <- grep("simR", colnames(fulldf))
for(k in 1:2){
  
  if(k==1){
    Vid = LVid
    Vid2 = LVid2
    Sid <- Lsid
    SideId <- LIDX
  }else if(k==2){
    Vid = RVid
    Vid2 = RVid2
    Sid <- Rsid
    SideId <- RIDX
  }
  
  for(i in uIds){
    
    subDf <- subset(fulldf, subID==i)
    for(n in 1:nrow(subDf)){
      
      V_S <- NA
      V_S2 <- NA
      ind <- subDf[n, SideId]
      prevs <- subDf$IdxChoose[1:(n-1)]
      
      
      indCP <- ind
      indCN <- ind-148
      prevsN <- prevs[which(prevs>148)] - 148
      prevsP <- prevs[which(prevs<149)]
      if(ind<149 & sum(prevs<149) > 0){
        curSimP <- similarity.dice(posGraph)[indCP,prevsP]
        
        prevFeed <- subDf$result[1:(n-1)]
        prevFeedP2 <- prevFeed[which(prevs<149)]
        prevFeedN2 <- prevFeed[which(prevs>148)]

        V_S = sum(curSimP * prevFeedP2) / sum(curSimP)
        
        curSimN <- rep(0, length(prevFeedN2))
      }

      if(ind>148 & sum(prevs>148) > 0 ){
        curSimN <- similarity.dice(negGraph)[indCN,prevsN]

        
        prevFeed <- subDf$result[1:(n-1)]
        prevFeedP2 <- prevFeed[which(prevs<149)]
        prevFeedN2 <- prevFeed[which(prevs>148)]
        V_S = sum(curSimN * prevFeedN2) / sum(curSimN)
        
        curSimP <- rep(0, length(prevFeedP2))
      }
      
      
      if( all(prevs>148) & ind < 149){
        V_S2 = 0
      }else if( all(prevs<149) == 1 & ind > 148){
        V_S2 = 0
      }else if(sum(prevs<149) == 0){
        V_S2 = sum(sum(curSimN * prevFeedN2)) / sum(c(prevFeedN2)) 
        curSim = c(curSimN)
      }else if(sum(prevs>148) == 0){
        V_S2 = sum(sum(curSimP * prevFeedP2)) / sum(c(prevFeedP2)) 
        curSim = c(curSimP)
      }else if(sum(prevs>148) > 0 & sum(prevs<149) > 0){
        V_S2 = sum(c(sum(curSimP * prevFeedP2), sum(curSimN * prevFeedN2))) / sum(c(prevFeedP2, prevFeedN2)) 
        curSim = c(curSimP,curSimN)
      }else{
        V_S2 = 0
      }
      
      if((n-1)==0){
        V_S=.50
        V_S2=0
      }
      
      if(is.na(V_S)){
        V_S=.50
      }

      if(is.na(V_S2)){
        V_S2=0
      }
      
      fulldf[fulldf$subID == i & fulldf$trialTotal==subDf$trialTotal[n], Vid] <- V_S
      fulldf[fulldf$subID == i & fulldf$trialTotal==subDf$trialTotal[n], Vid2] <- V_S2
      fulldf[fulldf$subID == i & fulldf$trialTotal==subDf$trialTotal[n], Sid] <- mean(curSim)
    }
    
  }
  
}

Simmat<-cbind(fulldf$simL, fulldf$simR)
fulldf$Simchoose <-Simmat[cbind(seq_along(fulldf$choice), fulldf$choice)]

```

```{r}
params <- read.csv("/Volumes/GoogleDrive/My Drive/Volumes/Research Project/Competing Motives/Data Analysis/Study2/Analysis/Study 2 Params/sim2CM_RBparams.csv")

  set.seed(132)
  uIds <- unique(fulldf$subID) # Extract unique subject IDs from dataset
  fulldf <- fulldf[order(fulldf$subID, fulldf$trialTotal),] # Sort by trials for trial-by-trial learning
  fulldf <- fulldf[!is.na(fulldf$choice),]
  x = c('trial', 'n', 'RPE', 'CSV', 'LSV', 'RSV', 'CVM', 'LVM', 'RVM', 'CValueB', 'LValueB', 'RValueB',  'AP' , 'lAP', 'rAP')

  core<-detectCores()
  cl <- parallel::makeCluster(core-2, setup_strategy = "sequential")
  setDefaultCluster(cl=cl)
  registerDoParallel(cl)
  clusterExport(cl, list("SimCM_RB"))
  clusterExport(cl, list("params"))
  clusterExport(cl, list("x"))
  clusterExport(cl, list("fulldf"))
  
result<-foreach(i=uIds, .combine = rbind.data.frame, .packages = c("compiler", "optimx")) %dopar% {
  output <- as.data.frame(matrix(ncol = length(x) ))
  names(output) <- x
  subDf <- subset(fulldf, subID == i) # Subset participant data
  # trialN, sideChoice, Left, Right, rew, DL, DR, simL, simR, param
  mat <- SimCM_RB(subDf$trialTotal, subDf$choice, subDf$result, subDf$desirLeft/7, subDf$desirRight/7, subDf$SV2_L, subDf$SV2_R, 
                     c( 
                       # mean(params$Temp[params$subID!=i]),
                       # mean(params$mix[params$subID!=i]),
                       # mean(params$rb[params$subID!=i])
                       params$Temp[params$subID==i],
                       params$mix[params$subID==i],
                       params$rb[params$subID==i]
                       
                       ) )
  output <- cbind(mat, data.frame(subID = i) )
  output
    
}
stopCluster(cl)  
LOO_Df <- result

LOO_Df <- LOO_Df %>% dplyr::rename(trialTotal = trial,
                  RLcount = n,
                  predError = RPE)
```

```{r}
fullTD <- merge(fulldf, LOO_Df, by = c("subID", "trialTotal"))
fullTD <- fullTD[order(fullTD$subID, fullTD$trialTotal),]
fullTD <- fullTD[!duplicated(fullTD[c("subID","trialTotal")]), ]
fullTD$chooseDes <- as.factor(fullTD$chooseDes)
```

```{r}
fullTD$greatSV <- NA
fullTD$greatSV <- ifelse(fullTD$LSV > fullTD$RSV, 1, ifelse(fullTD$RSV > fullTD$LSV, 2, 3))
fullTD$compMotC <- NA
fullTD$compMotC <- ifelse(fullTD$greatSV == fullTD$greatDes, 1, ifelse(fullTD$greatSV != fullTD$greatDes, 2, 3))

Idxmat<-cbind(fulldf$IdxLeft, fulldf$IdxRight)
fulldf$IdxChoose <- Idxmat[cbind(seq_along(fulldf$choice), fulldf$choice)]

SVmat <- cbind(fullTD$LSV, fullTD$RSV)
svAP <- t(apply(SVmat, 1, softmax))
colnames(svAP) <- c("LSV.AP", "RSV.AP")
fullTD <- cbind(fullTD, svAP)
fullTD$SV.AP <- svAP[cbind(seq_along(fullTD$choice), fullTD$choice)]

entropy <- function(probs){
  output <- ( -sum(probs * log(probs)) )
  return(output)
}


# function for how much conflict in motivation
relEntropy <- function(mat){
  LD<-mat[1]
  RD<-mat[2]
  LV<-mat[3]
  RV<-mat[4]
  maxEnt <- entropy(c(.5,.5))
  output <- (entropy(c(LD,RD)) / maxEnt)/ (entropy(c(LV,RV)) / maxEnt)
  return(output)
}

fullTD$relEnt <- NA
relEntMat <- cbind(fullTD$leftDesAP, fullTD$rightDesAP, fullTD$LSV.AP, fullTD$RSV.AP)
fullTD$relEnt <- apply(relEntMat, 1, relEntropy )
```

# Running Average

```{r}
fullTD$choice <- as.numeric(fullTD$choice)
fullTD <- fullTD[order(fullTD$subID, fullTD$trialTotal),]
fullTD$runAveL <- NA
fullTD$runAveR <- NA
fullTD$runAveC <- NA
fullTD$runSumL <- NA
fullTD$runSumR <- NA
fullTD$runSumC <- NA
fullTD$runSDL <- NA
fullTD$runSDR <- NA
fullTD$runSDC <- NA

LIDX <- grep("runAveL", colnames(fullTD))-1
LIDX2 <- grep("runSumL", colnames(fullTD))-1
LIDX3 <- grep("runSDL", colnames(fullTD))-1
output<-matrix(ncol=2,nrow=nrow(fullTD))
uIds <- unique(fullTD$subID)
for(u in uIds){
  subDf <- subset(fullTD, subID==u)
  cues <- cbind(subDf$leftCue, subDf$rightCue)
  for(c in 1:2){
    
    for(i in 1:nrow(subDf)){
      
    #curCue <- subDf$choiceCue[i]
    #curNotCue <- which(c(subDf$leftCue[i], subDf$rightCue[i])!=curCue) 
    curCue <- cues[i,c]
    curTrial <- subDf$trialTotal[i]
    subDf2 <- subDf[subDf$choiceCue==curCue,]
    subDf3 <- subDf2[subDf2$trialTotal < curTrial, ]
    
    if(nrow(subDf3)!=0){
      runAve <- mean(subDf3$result[1:nrow(subDf3)], na.rm=T)
      runSum <- sum(subDf3$result[1:nrow(subDf3)], na.rm=T)
      runSD <- sd(subDf3$result[1:nrow(subDf3)], na.rm=T)
    }else{
      # runAve <- 50
      runAve <- .50
      runSum <- 0
      runSD <- 0
    }
    
    fullTD[fullTD$subID == u & fullTD$trialTotal==curTrial, (LIDX+c)] <- runAve
    fullTD[fullTD$subID == u & fullTD$trialTotal==curTrial, (LIDX2+c)] <- runSum
    fullTD[fullTD$subID == u & fullTD$trialTotal==curTrial, (LIDX3+c)] <- runSD
    
    }
  }
}

aveMat <- cbind(fullTD$runAveL, fullTD$runAveR)
fullTD$runAveC <- aveMat[cbind(seq_along(fullTD$choice), fullTD$choice)]
sumMat <- cbind(fullTD$runSumL, fullTD$runSumR)
fullTD$runSumC <- sumMat[cbind(seq_along(fullTD$choice), fullTD$choice)]
sdMat <- cbind(fullTD$runSDL, fullTD$runSDR)
fullTD$runSumC <- sdMat[cbind(seq_along(fullTD$choice), fullTD$choice)]
fullTD$runAveRLDiff <- fullTD$runAveR - fullTD$runAveL


aveAP <- t(apply(aveMat, 1, softmax))
colnames(aveAP) <- c("aveL.AP", "aveR.AP")
fullTD <- cbind(fullTD, aveAP)
fullTD$aveC.AP <- aveAP[cbind(seq_along(fullTD$choice), fullTD$choice)]

# Group Average for Most Desirable
# fullTD$aveCD.AP <- NA
# greatDes12 <- fullTD$greatDes
# greatDes12[fullTD$greatDes==3] <- NA
# fullTD$aveCD.AP <- aveAP[cbind(seq_along(greatDes12), greatDes12)]

uc <- unique(fullTD$choice)
unchosen <- function(input){
  if(input==1){
    output<-2
  }else if(input==2){
    output<-1
  }else{
    output<-NA
  }
  return(output)
}
nochoice <- unlist(lapply(fullTD$choice, function(x) unchosen(x)))
fullTD$runAveUC <- aveMat[cbind(seq_along(nochoice), nochoice)]

fullTD$runAveCDiff <- fullTD$runAveC - fullTD$runAveUC
fullTD$outRminL <- fullTD$outRight - fullTD$outLeft
fullTD$inRminL <- fullTD$inRight - fullTD$inLeft
fullTD$aveRminL <- fullTD$runAveR - fullTD$runAveL
fullTD$sumRminL <- fullTD$runSumR - fullTD$runSumL

# choose trait with higher average?
fullTD$greatAveC <- as.numeric(apply(aveMat, 1, max)==fullTD$runAveC)

fullTD$desRminL <- fullTD$ZdesirRight - fullTD$ZdesirLeft
fullTD$rightCueYes = fullTD$rightCue >= fullTD$leftCue
fullTD$rightPropTYes = ifelse(fullTD$rightPropT == fullTD$leftPropT, 1, ifelse(fullTD$rightPropT > fullTD$leftPropT, 2, 3))
```

# Fixed Values

```{r}
fullTD$rightPV <- as.integer(fullTD$rightPropT)
fullTD$leftPV <- as.integer(fullTD$leftPropT)
fullTD$choosePV <- as.integer(fullTD$propTChoice)
fullTD$rightPV[fullTD$rightPV==1] <- .32
fullTD$rightPV[fullTD$rightPV==2] <- .50
fullTD$rightPV[fullTD$rightPV==3] <- .68
fullTD$leftPV[fullTD$leftPV==1] <- .32
fullTD$leftPV[fullTD$leftPV==2] <- .50
fullTD$leftPV[fullTD$leftPV==3] <- .68
fullTD$choosePV[fullTD$choosePV==1] <- .32
fullTD$choosePV[fullTD$choosePV==2] <- .50
fullTD$choosePV[fullTD$choosePV==3] <- .68
fullTD$PVRminL <- as.numeric(fullTD$rightPV) - as.numeric(fullTD$leftPV)
```

```{r}
fullTD$greatAve <- NA
fullTD$greatAve <- ifelse(fullTD$runAveL > fullTD$runAveR, 1, ifelse(fullTD$runAveR > fullTD$runAveL, 2, 3))
fullTD$compMotC2 <- NA
fullTD$compMotC2 <- ifelse(fullTD$greatAve == fullTD$greatDes, 1, ifelse(fullTD$greatAve != fullTD$greatDes, 2, 3))

fullTD$greatSum <- NA
fullTD$greatSum <- ifelse(fullTD$runSumL > fullTD$runSumR, 1, ifelse(fullTD$runSumR > fullTD$runSumL, 2, 3))
fullTD$compMotC3 <- NA
fullTD$compMotC3 <- ifelse(fullTD$greatSum == fullTD$greatDes, 1, ifelse(fullTD$greatSum != fullTD$greatDes, 2, 3))
```

```{r}
psych::phi(table(fullTD$compMotC, fullTD$compMotC2))
```


Gershman, 2015 (Adapt to distribution of rewards)

```{r}
# # split into 7 intervals
# bins<-cut(fullTD$RVB - fullTD$LVB, 7)
# binDf <- fullTD
# binDf$bins <- bins
# # what are the proportion of left/right choices at each interval
# output <- tapply(fullTD$choice, bins, function(x) prop.table(table(x)))
# # for pos
# outputP <- tapply(fullTD$choice[fullTD$valChoice==2], bins[fullTD$valChoice==2], function(x) prop.table(table(x)))
# # for neg
# outputN <- tapply(fullTD$choice[fullTD$valChoice==1], bins[fullTD$valChoice==1], function(x) prop.table(table(x)))
# 
# # extract cut intervals as numeric
# intervals <- read.table(text = gsub("[^.0-9]", " ", levels(bins)), col.names = c("lower", "upper"))
# # extract only even elements for right choice, put in dataframe
# output<-data.frame(bins = c(-intervals[1:4,1],intervals[5:7,2]),
#            empirical = as.numeric(unlist(output)[c(FALSE,TRUE)]))
# 
# plot(output)
```

```{r}

fullTD$desEnt <- apply(cbind(fullTD$leftDesAP, fullTD$rightDesAP), 1, entropy)
fullTD$apEnt <- apply(cbind(fullTD$rAP, fullTD$lAP), 1, entropy)
fullTD$aveEnt <- apply(cbind(fullTD$aveL.AP, fullTD$aveR.AP), 1, entropy)
fullTD$svEnt <- apply(cbind(fullTD$RSV.AP, fullTD$LSV.AP), 1, entropy)
```

```{r}
fullTD <- merge(fullTD, indDiff[c("subID", "conf", "decep", "SStatus","GStatus", "SocClass", "SE","NFC", "ENT", "NTB" , "SCC", "SING.Ind", "SING.Inter", "DS", "MemSE", "PrivCSE", "PubCSE", "IdImp", "SGO")], by="subID", all.x = T )
```



```{r}
setwd("~/Google Drive/Volumes/")
fullTD <- fullTD[order(fullTD$subID, fullTD$trialTotal),]
write.csv(fullTD, "./Research Project/Competing Motives/Data Analysis/Study2/output/fullDf.csv", row.names = FALSE)
```

```{r}
mat <- matrix(ncol = 5, nrow = (6 * length(unique(mergedRawr$subID))))
uIds <- unique(mergedRawr$subID)
k <- 1
for(i in uIds){
  for(j in 1:6){
    propTypeLeft <- unique(mergedRawt$leftPropT[mergedRawt$leftClust == j & mergedRawt$subID == i])
    propTypeRight <- unique(mergedRawt$rightPropT[mergedRawt$rightClust == j & mergedRawt$subID == i])
    propTypeChoice <- unique(mergedRawt$propTChoice[mergedRawt$clustChoice == j & mergedRawt$subID == i])
    mat[k, ] <- c(i, j, propTypeLeft, propTypeRight, propTypeChoice)
    k <- k + 1
  }
}
all(mat[1:nrow(mat), 3] == mat[1:nrow(mat), 4])
all(mat[1:nrow(mat), 4] == mat[1:nrow(mat), 5])
all(mat[1:nrow(mat), 3] == mat[1:nrow(mat), 5])
mat <- mat[1:nrow(mat), 1:3]
matN <- c("subID", "clustType", "propT")
clustPropTDf <- as.data.frame(mat)
names(clustPropTDf) <- matN
setwd("~/Google Drive/Volumes/")
#write.csv(clustPropTDf, "./Research Project/Competing Motives/Data Analysis/Study2/output/clustDf.csv", row.names = FALSE)
```

```{r}
mat <- matrix(ncol = 5, nrow = (6 * length(unique(mergedRawr$subID))))
uIds <- unique(mergedRawr$subID)
k <- 1
for(i in uIds){
  for(j in 1:6){
    propTypeLeft <- unique(mergedRawt$leftPropT[mergedRawt$leftClust == j & mergedRawt$subID == i])
    propTypeRight <- unique(mergedRawt$rightPropT[mergedRawt$rightClust == j & mergedRawt$subID == i])
    propTypeChoice <- unique(mergedRawt$propTChoice[mergedRawt$clustChoice == j & mergedRawt$subID == i])
    mat[k, ] <- c(i, j, propTypeLeft, propTypeRight, propTypeChoice)
    k <- k + 1
  }
}
all(mat[1:nrow(mat), 3] == mat[1:nrow(mat), 4])
all(mat[1:nrow(mat), 4] == mat[1:nrow(mat), 5])
all(mat[1:nrow(mat), 3] == mat[1:nrow(mat), 5])
mat <- mat[1:nrow(mat), 1:3]
matN <- c("subID", "clustType", "propT")
clustPropTDf <- as.data.frame(mat)
names(clustPropTDf) <- matN
```


```{r}
setwd("~/Google Drive/Volumes/")
clusterList <- read.csv("./Research Project/Competing Motives/Data Analysis/Study2/input/ClusterLists.csv")
names(mergedRawr)[colnames(mergedRawr)=="selfTrait"] <- "trait"
names(mergedRawr)[colnames(mergedRawr)=="trials_2.thisTrialN"] <- "trialTotal"
mergedRawr <- merge(mergedRawr, clusterList[c("trait", "clustType")], by = "trait")
cleanRe <- merge(mergedRawr, clustPropTDf, by = c("subID", "clustType") )
```



```{r}
cleanRe$cueType <- NA
for (i in 1:nrow(cleanRe)) {

if (cleanRe$propT[i] == 1 & cleanRe$valence[i] == 1){
    cleanRe$cueType[i] <- 1
}
if (cleanRe$propT[i] == 2 & cleanRe$valence[i] == 1){
    cleanRe$cueType[i] <- 2
}
if (cleanRe$propT[i] == 3 & cleanRe$valence[i] == 1){
    cleanRe$cueType[i] <- 3
}
if (cleanRe$propT[i] == 1 & cleanRe$valence[i] == 2){
    cleanRe$cueType[i] <- 4
}
if (cleanRe$propT[i] == 2 & cleanRe$valence[i] == 2){
    cleanRe$cueType[i] <- 5
}
if (cleanRe$propT[i] == 3 & cleanRe$valence[i] == 2){
    cleanRe$cueType[i] <- 6
}
}
```

```{r}
unseenFull <- data.frame()
for(i in uIds){
  subDfle <- subset(fullTD, subID ==  i)
  subDfre <- subset(cleanRe, subID == i)
  traitLe <- subDfle$traitChoice
  traitRe <- subDfre$trait
  unseen <- data.frame(subID = i, trait = setdiff(traitRe, traitLe), unseen = 1)
  unseenFull <- rbind(unseenFull, unseen)
  
}
cleanRe <- merge(cleanRe, unseenFull, by = c("subID", "trait"), all.x = TRUE)
cleanRe$unseen[is.na(cleanRe$unseen)] <- 0
```


```{r}
fullTD <- fullTD[order(fullTD$subID, fullTD$trialTotal),]
uIds <- unique(fullTD$subID)
uCue <- unique(fullTD$choiceCue)
cleanRe$aveCueF <- NA
cleanRe$aveCueTF <- NA
cleanRe$sumCue <- NA
cleanRe$aveSD <- NA
for(i in uIds){
  subDf <- fullTD[fullTD$subID==i,]
  for(j in uCue){
    cueDf <- subDf[subDf$choiceCue==j,]
    aveCue <- mean(cueDf$result, na.rm = T)
    aveSD <- sd(cueDf$result, na.rm = T)
    sumCue <- sum(cueDf$result, na.rm = T)
    aveCueStat <- mean(cueDf$result, na.rm=T)/(var(cueDf$result, na.rm=T)/sqrt( length(cueDf$result) ) )
    
    cleanRe$aveCueF[cleanRe$subID == i & cleanRe$cueType==j] <- aveCue
    cleanRe$aveSD[cleanRe$subID == i & cleanRe$cueType==j] <- aveSD
    cleanRe$aveCueTF[cleanRe$subID == i & cleanRe$cueType==j] <- aveCueStat
    cleanRe$sumCueF[cleanRe$subID == i & cleanRe$cueType==j] <- sumCue
  }
}
```



```{r}
allCombCents[colnames(allCombCents)=="valence"] <- NULL
fullDf <- merge(cleanRe, allCombCents, by = "trait")
```


```{r}
fullTD <- fullTD[order(fullTD$subID, fullTD$trialTotal),]
uIds <- unique(fullTD$subID)
fullDf$SV_F <- NA
fullDf$valEstF <- NA
for(i in uIds){
  subDf <- fullTD[fullTD$subID==i,]
  # weiNum <- grep("w1", colnames(subDf))
  # c <- weiNum - 1
  rCue <- unique(fullDf$Idx[fullDf$subID==i])
  uCue <- unique(subDf$IdxChoose)
  
  for(j in rCue){
      
      V_S <- NA
      V_S2 <- NA
      prevs <- uCue
      ind <- j
      
      indCP <- ind
      indCN <- ind-148
      prevsN <- prevs[which(prevs>148)] - 148
      prevsP <- prevs[which(prevs<149)]
      if(ind<149 & sum(prevs<149) > 0){
        curSimP <- similarity.dice(posGraph)[indCP,prevsP]
        
        prevFeed <- subDf$result
        prevFeedP2 <- prevFeed[which(prevs<149)]
        prevFeedN2 <- prevFeed[which(prevs>148)]

        V_S = sum(curSimP * prevFeedP2) / sum(curSimP)
        
        curSimN <- rep(0, length(prevFeedN2))
      }

      if(ind>148 & sum(prevs>148) > 0 ){
        curSimN <- similarity.dice(negGraph)[indCN,prevsN]

        
        prevFeed <- subDf$result
        prevFeedP2 <- prevFeed[which(prevs<149)]
        prevFeedN2 <- prevFeed[which(prevs>148)]
        V_S = sum(curSimN * prevFeedN2) / sum(curSimN)
        
        curSimP <- rep(0, length(prevFeedP2))
      }
      
      if( all(prevs>148) & ind < 149){
        V_S2 = 0
      }else if( all(prevs<149) == 1 & ind > 148){
        V_S2 = 0
      }else if(sum(prevs<149) == 0){
        V_S2 = sum(sum(curSimN * prevFeedN2)) / sum(c(prevFeedN2)) 
        curSim = c(curSimN)
      }else if(sum(prevs>148) == 0){
        V_S2 = sum(sum(curSimP * prevFeedP2)) / sum(c(prevFeedP2)) 
        curSim = c(curSimP)
      }else if(sum(prevs>148) > 0 & sum(prevs<149) > 0){
        V_S2 = sum(c(sum(curSimP * prevFeedP2), sum(curSimN * prevFeedN2))) / sum(c(prevFeedP2, prevFeedN2)) 
        curSim = c(curSimP,curSimN)
      }else{
        V_S2 = 0
      }
      
      fullDf$Sim[fullDf$subID == i & fullDf$Idx==j] <- mean(curSim)
      fullDf$SV_F[fullDf$subID == i & fullDf$Idx==j] <- V_S2
      fullDf$valEstF[fullDf$subID == i & fullDf$Idx==j] <- V_S2 * params$mix[params$subID==i] + (allCombCents$desirability[allCombCents$Idx==j]/7) * (1 - params$mix[params$subID==i])
      
  }
}
```

```{r}
setwd("~/Google Drive/Volumes/")
fullDf <- merge(fullDf, indDiff[c("subID", "conf", "decep", "SStatus","GStatus", "SocClass", "SE","NFC", "ENT", "NTB" , "SCC", "SING.Ind", "SING.Inter", "DS", "MemSE", "PrivCSE", "PubCSE", "IdImp", "SGO")], by="subID", all.x = T )
fullDf <- fullDf[order(fullDf$subID, fullDf$trialTotal),]
write.csv(fullDf, "./Research Project/Competing Motives/Data Analysis/Study2/output/reEvalDf.csv", row.names = FALSE)
```



