---
title: "feedback_merge+clean"
output: html_document
---

```{r}
library(compiler)
library(readbulk) 
library(psych)
library(forcats)
library(igraph)
library(MASS)
library(lme4)
library(cluster)
library(Kendall)
library(readr)
library(psych)
library(igraph)
library(plyr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(tidyr)
library(gtools)
library(sjstats)
library(brms)
library(optimx)
library(igraph)
library(loo)
cOptimx <- cmpfun(optimx)

```

```{r}
setwd("~/Google Drive/Volumes/")
posDf <- read.csv("./Research Project/Trait Network_Behaviral/generating network/output/adjacencyMatrix_p.csv")
posMat <- as.matrix(posDf)
posGraph <- graph.adjacency(posMat)
negDf <- read.csv("./Research Project/Trait Network_Behaviral/generating network/output/adjacencyMatrix_n.csv")
negMat <- as.matrix(negDf)
negGraph <- graph.adjacency(negMat)
```

```{r}
setwd("~/Google Drive/Volumes/Research Project/")
allPosCents <- read.csv("/Volumes/GoogleDrive/My Drive/Volumes/Research Project/Trait Network_Behaviral/generating network/output/allPosCents.csv")
allNegCents <- read.csv("/Volumes/GoogleDrive/My Drive/Volumes/Research Project/Trait Network_Behaviral/generating network/output/allNegCents.csv")
allCombCents <- rbind(allPosCents, allNegCents)
allCombCents$Idx <- 1:296
```

```{r}
mergedRaw <- read_bulk(directory = "./input/Task Data/", extension = ".csv", fun = read.csv)
```


```{r}
mergedRaw$choiceResp[mergedRaw$choiceResp==-99] <- NA
mergedRaw$optionChoice[mergedRaw$optionChoice==-99] <- NA
mergedRaw$SE.keys[mergedRaw$SE.keys=="space"] <- NA
mergedRaw$SE.keys <- as.numeric(mergedRaw$SE.keys)
```


```{r}
mergedRaw <- mergedRaw %>% rename(subID = participant, 
                     trialTotalT1 = trials_2.thisTrialN, 
                     trialTotalT2 = choices.thisTrialN,
                     selfResp = SE.keys,
                     sideChoice = choiceResp)

mergedRaw$trialTotalT1 <- mergedRaw$trialTotalT1 + 1
mergedRaw$trialTotalT2 <- mergedRaw$trialTotalT2 + 1

mergedRawtrain <- mergedRaw[!is.na(mergedRaw$trialTotalT1),]
mergedRawtest <- mergedRaw[!is.na(mergedRaw$trialTotalT2),]

Estimators <- mergedRaw %>% 
  select(subID, Estimator) %>%
  group_by(subID) %>%
  filter(row_number()==1)

rawTrain <- mergedRawtrain %>%
  select(subID, trait, trialTotalT1, selfResp)

rawTest <- mergedRawtest %>%
  select(subID, traitC, trialTotalT2, sideChoice, optionChoice, optionLeft, optionRight)

rawTest <- rawTest %>%
  rename(trait = traitC)

rawTest <- rawTest %>% inner_join(Estimators, by = "subID")
rawTrain <- rawTrain %>% inner_join(Estimators, by = "subID")

mergeTest <- rawTest %>% inner_join(allCombCents, by="trait")
mergeTrain <- rawTrain %>% inner_join(allCombCents, by="trait")

#mergeTest$ingChoice <- ifelse(is.na(mergeTest$ingChoice), NA, ifelse(mergeTest$optionChoice==mergeTest$Estimator, "Ingroup", "Outgroup"))

mergeTest$ingChoice <- ifelse(mergeTest$optionChoice==mergeTest$Estimator, "Ingroup", "Outgroup")
mergeTest$ingChoice <- as.factor(mergeTest$ingChoice)
mergeTest$ingChoiceN <- ifelse(mergeTest$ingChoice=="Ingroup", 1, 0)

```

```{r}
uSubs <- unique(mergeTest$subID)
mergeTest$SE <- NA
mergeTest$novel <- 0

for(i in uSubs){
  testSub <- subset(mergeTest, subID==i)
  trainSub <- subset(mergeTrain, subID==i)
  simMat <- similarity.dice(posGraph)
  
  curNovel <- setdiff(testSub$Idx, trainSub$Idx)
  mergeTest$novel[which(mergeTest$subID==i & mergeTest$Idx %in% curNovel)] <- 1
  
  for(t in 1:nrow(testSub)){
    trialNum <- testSub$trialTotalT2[t]
    curSims <- simMat[trainSub$Idx, testSub$Idx[t]]
    curSelf <- trainSub$selfResp
    curOut <- trainSub$outDegree
    curIn <- trainSub$inDegree
    curRem <- which(is.na(trainSub$selfResp))
    if(length(curRem)>0){
      curSelf <- curSelf[-curRem]
      curSims <- curSims[-curRem]
      curOut <- curOut[-curRem]
      curIn <- curIn[-curRem]
    }
    weightedAve <- sum(curSelf * curSims) / sum(curSelf)
    weightedOutAve <- sum(curSelf * curOut * curSims) / sum(curOut * curSelf)
    weightedInAve <- sum(curSelf * curIn * curSims) / sum(curIn * curSelf)
    mergeTest$SE[mergeTest$subID==i & mergeTest$trialTotalT2==trialNum] <- weightedAve
    mergeTest$oSE[mergeTest$subID==i & mergeTest$trialTotalT2==trialNum] <- weightedOutAve
    mergeTest$iSE[mergeTest$subID==i & mergeTest$trialTotalT2==trialNum] <- weightedInAve
    
  }
  
}
```

# 59353 has two CSVs. I deleted the first

```{r}
for(i in uSubs){
  if(nrow(mergeTest[mergeTest$subID==i,])>148){
    print(paste0("Subject ", i, " has more than one CSV"))
  }
}
```


```{r}
mergeTest2 <- mergeTrain %>% select(subID, trait, selfResp) %>% right_join(mergeTest, by = c("subID","trait"))
mergeTest3 <- merge(mergeTest, mergeTrain[c("subID","trait","selfResp")], by = c("subID","trait"), all.x = T)
mergeTest2<-mergeTest2[order(mergeTest2$subID, mergeTest2$trialTotalT2),]

# for(i in uSubs){
#   print(i)
#   print(  nrow(mergeTest[mergeTest$subID==i,]) )
#   print( nrow(mergeTest2[mergeTest2$subID==i,]) )
# }

mergeTest <- mergeTest2
```



# Flag careless task participant

```{r}
sketchMat <- matrix(nrow=length(uSubs),ncol=5)
for(i in 1:length(uSubs) ){
  testSub <- subset(mergeTest, subID==uSubs[i])
  trainSub <- subset(mergeTrain, subID==uSubs[i])
  
  proportionSelfs <- prop.table(table(trainSub$selfResp))
  proportionChoices <- prop.table(table(testSub$sideChoice))
  naSelfs <- sum(is.na(trainSub$selfResp))/length(trainSub$selfResp)
  naChoices <- sum(is.na(testSub$sideChoice))/length(testSub$sideChoice)
  
  sketchMat[i, ] <- c(uSubs[i], max(proportionSelfs), max(proportionChoices), naSelfs, naChoices)
}
colnames(sketchMat) <- c("subID", "propSelf", "propChoice", "naSelf", "naChoice")
sketchMat <- as.data.frame(sketchMat)

# Criteria:
# Over 80% of same self-evaluations
# Over 95% of same choices
# Over 40% missing responses for self-evaluations
# Over 40% missing responses for choices
sketchMat$sketch <- ifelse(sketchMat$propSelf > .80 | sketchMat$propChoice > .95 | sketchMat$naSelf > .40 | sketchMat$naChoice > .40, 1, 0)
```

```{r}
postQs <- read.csv("./input/Qualtrics Data/SA1postQs.csv")
preQs <- read.csv("./input/Qualtrics Data/SA1preQs.csv")
preQs$id[which(duplicated(preQs$id))]
preQs <- preQs %>% group_by(id) %>% filter(duplicated(id) | n()==1)

postQs$id[which(duplicated(postQs$id))]
#preQs <- preQs[-which(duplicated(preQs$id)),]

indDiff <- postQs %>% left_join(preQs, by="id")

# Duplicate IDs?
indDiff$id[which(duplicated(indDiff$id))]

indDiff <- indDiff %>% rename(subID = id)
```

```{r}
indDiff$SCC

# Reverse code Self-Concept Clarity Scale items
SCC_revcols = c("SCC_1", "SCC_2", "SCC_3", "SCC_4", "SCC_5", "SCC_7", 
                 "SCC_8", "SCC_9", "SCC_10", "SCC_12")
indDiff[ ,SCC_revcols] = 6 - indDiff[ ,SCC_revcols]
ind1 <- grep("SCC_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("SCC_12", colnames(indDiff))
ind2<-max(ind2)
# Compute score for Self-Concept Clarity Scale items
indDiff$SCC = rowMeans(indDiff[,ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])

psych::omega(indDiff[ind1:ind2])
```

Singelis Self-Construal
```{r}
# Compute score for Independence in Singelis Self-Construal Scale
SING.IndCol = c("SING.1", "SING.2", "SING.5", "SING.7", "SING.9", "SING.10", "SING.13", 
                 "SING.15", "SING.18", "SING.20", "SING.22", "SING.24", "SING.25",
                 "SING.27", "SING.29")
indDiff$SING.Ind = rowMeans(indDiff[, SING.IndCol], na.rm = TRUE)
# Compute score for Interdependence in Singelis Self-Construal Scale
SING.InterCol = c("SING.3", "SING.4", "SING.6", "SING.8", "SING.11", "SING.12", 
                   "SING.14", "SING.16", "SING.17", "SING.19", "SING.21", "SING.23",
                   "SING.26", "SING.28", "SING.30")
indDiff$SING.Inter = rowMeans(indDiff[, SING.InterCol], na.rm = TRUE)
# Compute score for Independence - Interdependence in Singelis Self-Construal Scale
indDiff$SING.IndPlus = (indDiff$SING.Ind - indDiff$SING.Inter)

psych::alpha(indDiff[SING.InterCol])
psych::alpha(indDiff[SING.IndCol])
```
Self-Esteem
```{r}
# Reverse code Rosenberg Self-Esteem items
SErevcols = c("RSE.2", "RSE.5", "RSE.6", "RSE.8", "RSE.9")
indDiff[ ,SErevcols] = 5 - indDiff[ ,SErevcols]
ind1 <- grep("RSE.1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("RSE.10", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Rosenberg Self-Esteem
indDiff$RSE = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items
NFCrevcols = c("NFC.6_3", "NFC.6_4")
indDiff[ ,NFCrevcols] = 8 - indDiff[ ,NFCrevcols]
ind1 <- grep("NFC.6_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("NFC.6_6", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$NFC = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items
NTBrevcols = c("NTB_1", "NTB_3", "NTB_7")
indDiff[ ,NTBrevcols] = 6 - indDiff[ ,NTBrevcols]
ind1 <- grep("NTB_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("NTB_10", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$NTB = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items


DSrevcols = c("DS_1", "DS_5", "DS_6", "DS_7", "DS_9", "DS_14")
indDiff[ ,DSrevcols] = 8 - indDiff[ ,DSrevcols]
ind1 <- grep("DS_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("DS_14", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$DS = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
ind1 <- grep("Proto_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("Proto_4", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$Proto = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)


psych::alpha(indDiff[ind1:ind2])
```


```{r}
indDiff <- indDiff %>% rename(conf = Off4_1, decep = Off5)

indDiffs <- indDiff %>% select(subID, ConDeb, conf, decep, Serious, UnderstandIns, UnderstandTr, Usable, DS, Proto, SCC, SI, RSE, NTB, NFC, SING.Ind, SING.Inter)

sketchMat <- indDiffs %>% select(subID, ConDeb, conf, decep, Serious, UnderstandIns, UnderstandTr, Usable) %>% inner_join(sketchMat, by = "subID")

sketchMat$remove <- ifelse(sketchMat$sketch > 0 | sketchMat$ConDeb == 2 | sketchMat$Usable == 2 | sketchMat$Serious < 4, 1, 0 | sketchMat$decep == 3)
```

```{r}
unique(mergeTest$subID)
cleanTest <- mergeTest[mergeTest$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(cleanTest$subID)
```

```{r}
unique(mergeTrain$subID)
cleanTrain <- mergeTrain[mergeTrain$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(cleanTrain$subID)
```

```{r}
unique(indDiffs$subID)
indDiffsclean <- indDiffs[indDiffs$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(indDiffsclean$subID)
```

```{r}
fullTest <- cleanTest %>% inner_join(indDiffsclean, by = "subID")
write.csv(fullTest, "./output/fullTest.csv", row.names = F)
```

```{r}
fullTest$optionChoiceN <- ifelse(fullTest$optionChoice=="Overestimator", 1, 0)
traitFreqOverUnder <- Rmisc::summarySE(fullTest, measurevar="optionChoiceN", groupvars = "trait")
write.csv(fullTest, "./output/traitFreqOverUnder.csv", row.names = F)
```

