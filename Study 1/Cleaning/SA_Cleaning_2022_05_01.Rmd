---
title: "feedback_merge+clean"
output: html_document
---

```{r}
library(ggeffects)
library(compiler)
library(readbulk) 
library(psych)
library(forcats)
library(igraph)
library(MASS)
library(lme4)
library(cluster)
library(Kendall)
library(readr)
library(psych)
library(igraph)
library(plyr)
library(dplyr)
library(ggplot2)
library(reshape2)
library(tidyr)
library(gtools)
library(sjstats)
library(brms)
library(optimx)
library(igraph)
library(loo)
cOptimx <- cmpfun(optimx)

```

```{r}
library(devtools)
source_url("https://raw.githubusercontent.com/JacobElder/Miscellaneous-R-Functions/master/assortativityNA.R")
```

```{r}
setwd("~/Google Drive/Volumes/")
posDf <- read.csv("./Research Project/Trait Network_Behaviral/generating network/output/adjacencyMatrix_p.csv")
posMat <- as.matrix(posDf)
posGraph <- graph.adjacency(posMat)
```

```{r}
setwd("~/Google Drive/Volumes/Research Project/")
allPosCents <- read.csv("/Volumes/GoogleDrive/My Drive/Volumes/Research Project/Trait Network_Behaviral/generating network/output/allPosCents.csv")
allNegCents <- read.csv("/Volumes/GoogleDrive/My Drive/Volumes/Research Project/Trait Network_Behaviral/generating network/output/allNegCents.csv")
allCombCents <- rbind(allPosCents, allNegCents)
allCombCents$Idx <- 1:296
```


```{r}
setwd("/Volumes/Research Project/Self-Anchoring/Cleaning/input/")
mergedRaw <- read_bulk(directory = ".", extension = ".csv", fun = read.csv)
paste0("There are ", length(unique(mergedRaw$File)), " unique participants")
```



```{r}
mergedRaw$choiceResp[mergedRaw$choiceResp==-99] <- NA
mergedRaw$optionChoice[mergedRaw$optionChoice==-99] <- NA
mergedRaw$SE.keys[mergedRaw$SE.keys=="space"] <- NA
mergedRaw$SE.keys <- as.numeric(mergedRaw$SE.keys)
```


```{r}

mergedRaw <- mergedRaw %>% rename(subID = participant, 
                     trialTotalT1 = trials_2.thisTrialN, 
                     trialTotalT2 = choices.thisTrialN,
                     selfResp = SE.keys,
                     sideChoice = choiceResp,
                     RT = resp.rt)

mergedRaw$trialTotalT1 <- mergedRaw$trialTotalT1 + 1
mergedRaw$trialTotalT2 <- mergedRaw$trialTotalT2 + 1

mergedRawtrain <- mergedRaw[!is.na(mergedRaw$trialTotalT1),]
mergedRawtest <- mergedRaw[!is.na(mergedRaw$trialTotalT2),]

Estimators <- mergedRaw %>% 
  select(subID, Estimator) %>%
  group_by(subID) %>%
  filter(row_number()==1)

rawTrain <- mergedRawtrain %>%
  select(subID, trait, trialTotalT1, selfResp)

rawTest <- mergedRawtest %>%
  select(subID, traitC, trialTotalT2, sideChoice, optionChoice, optionLeft, optionRight, RT)

rawTest <- rawTest %>%
  rename(trait = traitC)

rawTest <- rawTest %>% inner_join(Estimators, by = "subID")
rawTrain <- rawTrain %>% inner_join(Estimators, by = "subID")

mergeTest <- rawTest %>% inner_join(allCombCents, by="trait")
mergeTrain <- rawTrain %>% inner_join(allCombCents, by="trait")

#mergeTest$ingChoice <- ifelse(is.na(mergeTest$ingChoice), NA, ifelse(mergeTest$optionChoice==mergeTest$Estimator, "Ingroup", "Outgroup"))

mergeTest$ingChoice <- ifelse(mergeTest$optionChoice==mergeTest$Estimator, "Ingroup", "Outgroup")
mergeTest$ingChoice <- as.factor(mergeTest$ingChoice)
mergeTest$ingChoiceN <- ifelse(mergeTest$ingChoice=="Ingroup", 1, 0)
```

# Flag careless task participant

```{r}
uSubs <- unique(mergeTest$subID)
sketchMat <- matrix(nrow=length(uSubs),ncol=5)
for(i in 1:length(uSubs) ){
  testSub <- subset(mergeTest, subID==uSubs[i])
  trainSub <- subset(mergeTrain, subID==uSubs[i])
  
  proportionSelfs <- prop.table(table(trainSub$selfResp))
  proportionChoices <- prop.table(table(testSub$sideChoice))
  naSelfs <- sum(is.na(trainSub$selfResp))/length(trainSub$selfResp)
  naChoices <- sum(is.na(testSub$sideChoice))/length(testSub$sideChoice)
  
  sketchMat[i, ] <- c(uSubs[i], max(proportionSelfs), max(proportionChoices), naSelfs, naChoices)
}
colnames(sketchMat) <- c("subID", "propSelf", "propChoice", "naSelf", "naChoice")
sketchMat <- as.data.frame(sketchMat)

# Criteria:
# Over 80% of same self-evaluations
# Over 95% of same choices
# Over 40% missing responses for self-evaluations
# Over 40% missing responses for choices
sketchMat$sketch <- ifelse(sketchMat$propSelf > .80 | sketchMat$propChoice > .90 | sketchMat$naSelf > .40 | sketchMat$naChoice > .40, 1, 0)
```

```{r}
postQs <- read.csv("/Volumes/Research Project/Self-Anchoring/Cleaning/Qualtrics Data/SA1postQs.csv")
preQs <- read.csv("/Volumes/Research Project/Self-Anchoring/Cleaning/Qualtrics Data/SA1preQs.csv")
preQs$id[which(duplicated(preQs$id))]
preQs <- preQs %>% group_by(id) %>% filter(duplicated(id) | n()==1)

postQs$id[which(duplicated(postQs$id))]
#preQs <- preQs[-which(duplicated(preQs$id)),]

indDiff <- postQs %>% left_join(preQs, by="id")

# Duplicate IDs?
indDiff$id[which(duplicated(indDiff$id))]

indDiff <- indDiff[!duplicated(indDiff$id),]

indDiff <- indDiff %>% rename(subID = id)
```

```{r}
indDiff$SCC

# Reverse code Self-Concept Clarity Scale items
SCC_revcols = c("SCC_1", "SCC_2", "SCC_3", "SCC_4", "SCC_5", "SCC_7", 
                 "SCC_8", "SCC_9", "SCC_10", "SCC_12")
indDiff[ ,SCC_revcols] = 6 - indDiff[ ,SCC_revcols]
ind1 <- grep("SCC_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("SCC_12", colnames(indDiff))
ind2<-max(ind2)
# Compute score for Self-Concept Clarity Scale items
indDiff$SCC = rowMeans(indDiff[,ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])

psych::omega(indDiff[ind1:ind2])
```

Singelis Self-Construal
```{r}
# Compute score for Independence in Singelis Self-Construal Scale
SING.IndCol = c("SING.1", "SING.2", "SING.5", "SING.7", "SING.9", "SING.10", "SING.13", 
                 "SING.15", "SING.18", "SING.20", "SING.22", "SING.24", "SING.25",
                 "SING.27", "SING.29")
indDiff$SING.Ind = rowMeans(indDiff[, SING.IndCol], na.rm = TRUE)
# Compute score for Interdependence in Singelis Self-Construal Scale
SING.InterCol = c("SING.3", "SING.4", "SING.6", "SING.8", "SING.11", "SING.12", 
                   "SING.14", "SING.16", "SING.17", "SING.19", "SING.21", "SING.23",
                   "SING.26", "SING.28", "SING.30")
indDiff$SING.Inter = rowMeans(indDiff[, SING.InterCol], na.rm = TRUE)
# Compute score for Independence - Interdependence in Singelis Self-Construal Scale
indDiff$SING.IndPlus = (indDiff$SING.Ind - indDiff$SING.Inter)

psych::alpha(indDiff[SING.InterCol])
psych::alpha(indDiff[SING.IndCol])
```
Self-Esteem
```{r}
# Reverse code Rosenberg Self-Esteem items
SErevcols = c("RSE.2", "RSE.5", "RSE.6", "RSE.8", "RSE.9")
indDiff[ ,SErevcols] = 5 - indDiff[ ,SErevcols]
ind1 <- grep("RSE.1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("RSE.10", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Rosenberg Self-Esteem
indDiff$RSE = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items
NFCrevcols = c("NFC.6_3", "NFC.6_4")
indDiff[ ,NFCrevcols] = 8 - indDiff[ ,NFCrevcols]
ind1 <- grep("NFC.6_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("NFC.6_6", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$NFC = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items
NTBrevcols = c("NTB_1", "NTB_3", "NTB_7")
indDiff[ ,NTBrevcols] = 6 - indDiff[ ,NTBrevcols]
ind1 <- grep("NTB_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("NTB_10", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$NTB = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
# Reverse code Need for Cog items


DSrevcols = c("DS_1", "DS_5", "DS_6", "DS_7", "DS_9", "DS_14")
indDiff[ ,DSrevcols] = 8 - indDiff[ ,DSrevcols]
ind1 <- grep("DS_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("DS_14", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$DS = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)

psych::alpha(indDiff[ind1:ind2])
```

```{r}
ind1 <- grep("Proto_1", colnames(indDiff))
ind1<-min(ind1)
ind2<- grep("Proto_4", colnames(indDiff))
ind2<-max(ind2)
# Compute scores for Need for Cog
indDiff$Proto = rowMeans(indDiff[, ind1:ind2], na.rm = TRUE)


psych::alpha(indDiff[ind1:ind2])
```


```{r}
indDiff <- indDiff %>% rename(conf = Off4_1, decep = Off5)

indDiffs <- indDiff %>% select(subID, ConDeb, conf, decep, Serious, UnderstandIns, UnderstandTr, Usable, DS, Proto, SCC, SI, RSE, NTB, NFC, SING.Ind, SING.Inter)

sketchMat <- indDiffs %>% select(subID, ConDeb, conf, decep, Serious, UnderstandIns, UnderstandTr, Usable) %>% inner_join(sketchMat, by = "subID")

sketchMat$remove <- ifelse(sketchMat$sketch > 0 | sketchMat$ConDeb == 2 | sketchMat$Usable == 2 | sketchMat$Serious < 5, 1, 0 | sketchMat$decep < 1)
```

```{r}
unique(mergeTest$subID)
cleanTest <- mergeTest[mergeTest$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(cleanTest$subID)
```

```{r}
unique(mergeTrain$subID)
cleanTrain <- mergeTrain[mergeTrain$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(cleanTrain$subID)
```

```{r}
unique(indDiffs$subID)
indDiffsclean <- indDiffs[indDiffs$subID %in% sketchMat$subID[sketchMat$remove!=1],]
unique(indDiffsclean$subID)
```

# 59353 has two CSVs. I deleted the first

```{r}

uSubs <- unique(cleanTest$subID)
duplicatedIDs <- c()
for(i in uSubs){
  if(nrow(cleanTest[cleanTest$subID==i,])>148){
    print(paste0("Subject ", i, " has more than one CSV"))
    duplicatedIDs <- c(duplicatedIDs, i)
    
  }
}
```

# Check if repeated CSVs are identical

```{r}

repeatedIDs <- c()
for(t in 1:length(duplicatedIDs)){
  
  checkDup1 <- cleanTest %>%
  filter(subID==duplicatedIDs[t])

  outcome <- all( checkDup1[!duplicated(checkDup1$trait),] == checkDup1[duplicated(checkDup1$trait),], na.rm = T )
  repeatedIDs <- c(repeatedIDs, outcome)
  
}
duplicateFrame <- cbind(duplicatedIDs, repeatedIDs)
duplicateFrame
```

# Resolve duplicates

For IDs in which duplicate IDs have identical data, keep first instances. It doesn't matter.

For IDs in which duplicated IDs have different data, keep second data. More likely to be the accurate data.

```{r}

# subset duplicates

duplicatedDataTest <- cleanTest[cleanTest$subID %in% duplicatedIDs,]
duplicatedDataTrain <- cleanTrain[cleanTrain$subID %in% duplicatedIDs,]

# subset original data, excluding duplicates

'%!in%' <- function(x,y)!('%in%'(x,y))

originalDataTest <- cleanTest[cleanTest$subID %!in% duplicatedIDs,]
originalDataTrain <- cleanTrain[cleanTrain$subID %!in% duplicatedIDs,]

# Did indexing work?

nrow(originalDataTest) + nrow(duplicatedDataTest) == nrow(cleanTest)
nrow(originalDataTrain) + nrow(duplicatedDataTrain) == nrow(cleanTrain)

for(t in 1:nrow(duplicateFrame)){
  # if not identical data, keep last
  if(duplicateFrame[t,2]==0){
    curData <- duplicatedDataTest[duplicatedDataTest$subID==duplicatedIDs[t],]
    originalDataTest <- rbind(originalDataTest, curData[duplicated(curData$trait),])
    
    curData <- duplicatedDataTrain[duplicatedDataTrain$subID==duplicatedIDs[t],]
    originalDataTrain <- rbind(originalDataTrain, curData[duplicated(curData$trait),])
  # if identical data, keep first
  }else if(duplicateFrame[t,2]==1){
    curData <- duplicatedDataTest[duplicatedDataTest$subID==duplicatedIDs[t],]
    originalDataTest <- rbind(originalDataTest, curData[!duplicated(curData$trait),])
    
    curData <- duplicatedDataTrain[duplicatedDataTrain$subID==duplicatedIDs[t],]
    originalDataTrain <- rbind(originalDataTrain, curData[duplicated(curData$trait),])
  }
}

# Are all IDs identical as before?
all(unique(originalDataTest$subID) %in% unique(cleanTest$subID))
all(unique(originalDataTrain$subID) %in% unique(cleanTrain$subID))

# Are the appropriate number of rows reduced?
nrow(cleanTest) - nrow(originalDataTest) == length(duplicatedIDs)*148

cleanTest <- originalDataTest
cleanTrain <- originalDataTrain
```



```{r}
sigmoid <- function(feed, slope=1, shift=0){
  feed = feed - 4
  output = 1 / (1 + exp(slope * -(feed) - shift ) )
  output = (output * 6) + 1
  return(output)
}

entropy <- function(x){
  inds<-which(x!=0)
  -sum(x[inds] * log2(x[inds]))
}

computeNeighbors <- function(graph, label, type = "all"){
  curNeigh <- neighbors(graph, label, mode = type)
  curGraph <- induced.subgraph(graph, curNeigh)
  impInd <- which(!is.na(V(curGraph)$SE))
  impGraph <- induced.subgraph(curGraph, impInd)
  neighAveSE <- mean(V(impGraph)$SE, na.rm = TRUE)
  return(neighAveSE)
}
```

```{r}
evalMat <- matrix(nrow=148, ncol=1)
evalMat[,1] <- 1:148
evalMat <- as.data.frame(evalMat)
colnames(evalMat) <- c("Idx")
for(i in uSubs){
  eval <- cleanTrain$selfResp[cleanTrain$subID==i]
  cur <- cbind(cleanTrain$Idx[cleanTrain$subID==i], eval)
  colnames(cur) <- c("Idx",paste0("e",i))
  evalMat <- merge(evalMat, cur, by = "Idx", all.x = T)
}

library(magrittr)
library(dplyr)
library(ggpubr)

mds <- evalMat %>%
  select(2:length(.)) %>%
  dist() %>%          
  isoMDS(k=2) %>%
  .$points %>%
  as_tibble()
colnames(mds) <- c("Dim.1", "Dim.2")

# Plot MDS
ggscatter(mds, x = "Dim.1", y = "Dim.2", 
          label = allPosCents$trait,
          size = 1,
          repel = TRUE)

mds$Idx <- 1:148

mdsMat <- as.matrix(dist(mds[1:2]))
```


```{r}
cleanTest$SE <- NA
cleanTest$novel <- 0
simMat <- similarity.dice(posGraph)
allPosCents$Idx <- 1:148

for(i in uSubs){
  testSub <- subset(cleanTest, subID==i)
  trainSub <- subset(cleanTrain, subID==i)
  
  curNovel <- setdiff(testSub$Idx, trainSub$Idx)
  cleanTest$novel[which(cleanTest$subID==i & cleanTest$Idx %in% curNovel)] <- 1
  
  
  subAllSelf <- trainSub %>% select(Idx, selfResp) %>% full_join(allPosCents, by = "Idx") %>% arrange(Idx)
  
  for(t in 1:nrow(testSub)){
    trialNum <- testSub$trialTotalT2[t]
    curSims <- simMat[trainSub$Idx, testSub$Idx[t]]
    curMDS <- mdsMat[trainSub$Idx, testSub$Idx[t]]
    curSelf <- trainSub$selfResp
    curOut <- trainSub$outDegree
    curIn <- trainSub$inDegree
    curRem <- which(is.na(trainSub$selfResp))
    if(length(curRem)>0){
      curSelf <- curSelf[-curRem]
      curSims <- curSims[-curRem]
      curOut <- curOut[-curRem]
      curIn <- curIn[-curRem]
    }
    weightedAve <- sum(curSelf * curSims) / sum(curSelf)
    weightedOutAve <- sum(curSelf * curOut * curSims) / sum(curOut * curSelf)
    weightedInAve <- sum(curSelf * curIn * curSims) / sum(curIn * curSelf)
    weightedAveS <- sum(sigmoid(curSelf) * curSims) / sum(sigmoid(curSelf))
    
    cleanTest$SE[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- weightedAve
    cleanTest$oSE[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- weightedOutAve
    cleanTest$iSE[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- weightedInAve
    cleanTest$sSE[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- weightedAveS
    cleanTest$eSE[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- exp(weightedAve)
    
    weightedMDS <- sum(curSelf * curMDS) / sum(curSelf)
    
    cleanTest$meanSim[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- mean(curSims)
    cleanTest$meanMDS[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- mean(curMDS)
    cleanTest$weightMDS[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- weightedMDS
    
    weightedAve <- sum(curSelf * curSims) / sum(curSims)
    weightedOutAve <- sum(curSelf * curOut * curSims) / sum(curOut * curSims)
    weightedInAve <- sum(curSelf * curIn * curSims) / sum(curIn * curSims)
    
    cleanTest$WSR[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- weightedAve
    cleanTest$oWSR[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- weightedOutAve
    cleanTest$iWSR[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- weightedInAve
    
    cleanTest$fam[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- sum(curSims)
    
    classMat <- matrix(nrow=7,ncol=1)
    sumSims <- sum(curSims)
    for(e in 1:7){
      classIndices<-which(curSelf==e)
      classIdx<-trainSub$Idx[classIndices]
      classMat[e] <- sum(simMat[classIdx,testSub$Idx[t]])/sumSims
      #classSim <- simMat[trainSub$Idx[classIndices],testSub$Idx[t]]
      
    }
    cleanTest$entropy[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- entropy(classMat)
    classMat<-cbind(classMat,1:7)
    classMat <- as.data.frame(classMat)
    cleanTest$slope[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <-lm(classMat$V1 ~ classMat$V2)$coefficients[[2]]
    cleanTest$nlslope[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- MannKendall(classMat$V1)$tau[[1]]
    
    if(length(subAllSelf$selfResp)!=148){
      print("I am unhappy, fix me")
      print(paste0("Subject ",i," Trial ", t))
      break
    }
    V(posGraph)$SE <- subAllSelf$selfResp
    
    cleanTest$seHomoph[cleanTest$subID==i] <- assortativityNA(posGraph, V(posGraph)$SE+.001)
    
  traitIdx <- cleanTest$Idx[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum]
  curLabel <- paste0("V",traitIdx)
  
  cleanTest$neighAveInSE[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- computeNeighbors(posGraph, curLabel, "in")
  cleanTest$neighAveOutSE[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- computeNeighbors(posGraph, curLabel, "out")
  cleanTest$neighAveAllSE[cleanTest$subID==i & cleanTest$trialTotalT2==trialNum] <- computeNeighbors(posGraph, curLabel, "all")
   
  }
  
}
```

```{r}
trainSimMat <- matrix(ncol=7,nrow=0)
testSimMat <- matrix(ncol=6,nrow=0)
for(i in uSubs){
  testSub <- subset(cleanTest, subID==i)
  trainSub <- subset(cleanTrain, subID==i)
  
  curNovel <- setdiff(testSub$Idx, trainSub$Idx)
  cleanTest$novel[which(cleanTest$subID==i & cleanTest$Idx %in% curNovel)] <- 1
  
  allIdx <- trainSub$Idx
  allSelf <- trainSub$selfResp
  allIdxTest <- testSub %>% filter(novel==1) %>% select(Idx) %>% pull(Idx)
  for(t in 1:nrow(trainSub)){
    curIdx <- trainSub$Idx[t]
    curSelf <- trainSub$selfResp[t]
    allSim <- simMat[curIdx, allIdx]
    
    WeightAve <- sum(allSim*allSelf, na.rm = T)/sum(allSim, na.rm = T)
    
    curMat <- cbind(rep(i,length(allSelf)),
                    rep(curSelf,length(allSelf)),
                    rep(curIdx,length(allSelf)),
                    allIdx,
                    allSelf,
                    allSim,
                    WeightAve
                    )
    trainSimMat <- rbind(trainSimMat,curMat)
  
    allSimTest <- simMat[curIdx, allIdxTest]
    curMatTest <- cbind(rep(i, length(allSimTest)),
                        rep(curSelf,length(allSimTest)),
                        rep(curIdx,length(allSimTest)),
                        allIdxTest, 
                        allSimTest,
                        WeightAve
                        )
    testSimMat <- rbind(testSimMat,curMatTest)
    
    
  trialNumT1 <- trainSub$trialTotalT1[t]
  cleanTrain$inGsim[cleanTrain$subID==i & cleanTrain$trialTotalT1==trialNumT1] <- mean(simMat[trainSub$Idx[t],testSub$Idx[which(testSub$ingChoiceN==1)]])
  cleanTrain$outGsim[cleanTrain$subID==i & cleanTrain$trialTotalT1==trialNumT1] <- mean(simMat[trainSub$Idx[t],testSub$Idx[which(testSub$ingChoiceN==0)]])
    
    
  }
  
  V(posGraph)$C <- testSub$ingChoice[order(testSub$Idx)]
  cleanTest$groupHomoph[cleanTest$subID==i] <- netseg::assort(posGraph, "C")
  
}
colnames(trainSimMat) <- c("subID","self", "Idx", "targetIdx", "targetSelf", "similarity", "WA")
colnames(testSimMat) <- c("subID","self", "Idx", "targetIdx", "similarity", "WA")
trainSimDf <- as.data.frame(trainSimMat)
testSimDf <- as.data.frame(testSimMat)

cleanTrain$inOutDiff <- cleanTrain$inGsim - cleanTrain$outGsim
```

```{r}
    # curDfTrain<-as.data.frame(curMat)
    # colnames(curDfTrain) <- c("subID","self", "Idx", "targetIdx", "targetSelf", "similarity")
    # curDfTest<-as.data.frame(curMatTest)
    # colnames(curDfTest) <- c("subID","self", "Idx", "targetIdx", "similarity")
    # lm(targetSelf ~ scale(self) * scale(similarity), data=curDfTrain )
    # curMatTest <- cbind(curMatTest, predict(m, curDfTest))
```


```{r}
library(lmerTest)
m <- lmer(targetSelf ~ scale(self) * scale(similarity) + ( scale(self) + scale(similarity) | subID) + ( 1 | Idx), data = trainSimDf)
summary(m)
ggpredict(m, c("self","similarity")) %>% plot(show.title=F)+ xlab("Reference Self-Descriptiveness") + ylab("Target Self-Descriptiveness") + jtools::theme_apa()  + scale_color_discrete(labels = c("Low Similarity","Moderate Similarity", "High Similarity"))
ggsave("~/Documents/UC Riverside/Studies/Self-Anchoring/Figures/TrainingPredictedEffects.tiff",dpi=600)
trainSimDf$predicted <- predict(m, trainSimDf)
testSimDf$predicted <- predict(m, testSimDf)

trainAvePredicted <- Rmisc::summarySE(data=trainSimDf, measurevar = "predicted", groupvars = c("subID","targetIdx"))
testAvePredicted <- Rmisc::summarySE(data=testSimDf, measurevar = "predicted", groupvars = c("subID","targetIdx"), na.rm=T)
trainAvePredicted <- trainAvePredicted %>% rename(Idx = targetIdx)
testAvePredicted <- testAvePredicted %>% rename(Idx = targetIdx)

predictedEvals <- rbind(testAvePredicted, trainAvePredicted)
allPosCents$Idx <- 1:148
predictedEvals <- merge(predictedEvals, allPosCents, by = "Idx")
```


```{r}
cleanTest2 <- cleanTrain %>% select(subID, trait, selfResp) %>% full_join(cleanTest, by = c("subID","trait"))
#cleanTest3 <- merge(cleanTest, cleanTrain[c("subID","trait","selfResp")], by = c("subID","trait"), all.x = T)
cleanTest2<-cleanTest2[order(cleanTest2$subID, cleanTest2$trialTotalT2),]
```

```{r}
nrow(subset(cleanTest2, subID==uSubs[1]))
```


```{r}
cleanTest4 <- predictedEvals %>% select(subID, trait, predicted) %>% full_join(cleanTest2, by = c("subID","trait"))
#cleanTest3 <- merge(cleanTest, cleanTrain[c("subID","trait","selfResp")], by = c("subID","trait"), all.x = T)
cleanTest4<-cleanTest4[order(cleanTest4$subID, cleanTest4$trialTotalT2),]

cleanTest <- cleanTest4
```

```{r}
fullTest <- cleanTest %>% inner_join(indDiffsclean, by = "subID")
write.csv(fullTest, "./output/fullTest.csv", row.names = F)
write.csv(cleanTrain, "./output/fullTrain.csv", row.names = F)
```

```{r}
fullTest$optionChoiceN <- ifelse(fullTest$optionChoice=="Overestimator", 1, 0)

traitFreqOverUnder <- Rmisc::summarySE(fullTest, measurevar="optionChoiceN", groupvars = "trait", na.rm = T)
write.csv(traitFreqOverUnder, "./output/traitFreqOverUnder.csv", row.names = F)
```

